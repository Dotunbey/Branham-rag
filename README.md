# ğŸ¦… Branham-RAG

**A NotebookLMâ€‘Grade Retrievalâ€‘Augmented AI for Large Sermon Archives**

---

## ğŸ“Œ Overview

**Branham-RAG** is a productionâ€‘ready **Retrievalâ€‘Augmented Generation (RAG)** system designed to deliver **accurate, referenceâ€‘grounded answers and summaries** over a large historical sermon corpus.

Unlike typical chatbot demos, this system emphasizes:

* Deterministic parsing and metadata extraction
* Identityâ€‘preserving chunking
* Hybrid retrieval (keyword + semantic + seriesâ€‘aware)
* Doctrineâ€‘faithful, structured generation
* Verifiable references that link directly to original sermon sources

The architecture and design philosophy are intentionally aligned with systems like **NotebookLM**, prioritizing **accuracy, traceability, and interpretability** over raw fluency.

---

## ğŸ¯ Key Features

### ğŸ”¹ Robust PDF Ingestion Pipeline

* Filenameâ€‘based metadata extraction (date code, title)
* Visual header and pageâ€‘noise removal
* Paragraphâ€‘accurate parsing aligned with original transcripts
* Page start/end tracking per paragraph
* Identityâ€‘preserving handling of very large (â€œmonsterâ€) paragraphs
* Incremental ingestion (new sermons can be added without reprocessing old data)

---

### ğŸ”¹ Deterministic Metadata & Citation Safety

Every text chunk retains stable metadata, including:

* Sermon filename
* Date code (e.g. `62â€‘0909E`)
* Paragraph number
* Page range
* Stable chunk identity

This ensures:

* No duplicate vectors
* No broken references
* Predictable citation behavior
* Safe reâ€‘ingestion and resume support

---

### ğŸ”¹ Hybrid Retrieval Engine (NotebookLMâ€‘Style)

The retriever combines **four complementary strategies**:

1. **Explicit sermon targeting**
   Example: *â€œSummarize In His Presenceâ€*

2. **Seriesâ€‘aware retrieval**
   Correctly prioritizes canonical series (e.g. the 1963 Seven Seals sermons)

3. **Local keyword & BM25 ranking**
   Highâ€‘recall matching for exact phrases and terminology

4. **Cloud semantic search (Pinecone)**
   Highâ€‘precision embeddingâ€‘based retrieval

Results are **deduplicated, ranked, and merged deterministically** before being passed to the LLM.

---

### ğŸ”¹ Doctrineâ€‘Safe Prompt Engineering

The system prompt enforces:

* Faithful paraphrasing (no invented doctrine)
* Clear structural output (headings and bullet points)
* Explicit explanation of symbols
* Calm, historical preaching tone
* Explicit uncertainty when the source text is silent
* Strict avoidance of hallucinated citations

This significantly reduces misrepresentation risk and improves trustworthiness.

---

### ğŸ”¹ Streamlit UI (Productionâ€‘Focused UX)

* Chat mode for conversational Q&A
* Search mode for direct paragraph discovery
* Immediate, clickable references
* Mobileâ€‘friendly sidebar behavior
* Structured output rendering (headings, bullets, paragraphs preserved)
* Deepâ€‘linking to original sermons on MessageHub

---

## ğŸ§  Architecture Overview

```
PDFs
 â””â”€â”€ Ingestion Engine
      â”œâ”€â”€ Metadata Extraction
      â”œâ”€â”€ Page & Paragraph Parsing
      â”œâ”€â”€ Chunk Identity Control
      â””â”€â”€ Incremental Cache (Pickle)

Chunks
 â”œâ”€â”€ Local Search (BM25)
 â”œâ”€â”€ Vector Store (Pinecone)
 â””â”€â”€ Hybrid Retriever
      â””â”€â”€ LLM (Gemini)

Streamlit UI
 â”œâ”€â”€ Chat Mode
 â”œâ”€â”€ Search Mode
 â””â”€â”€ Reference Linking
```

---

## ğŸ› ï¸ Tech Stack

| Layer               | Technology           |
| ------------------- | -------------------- |
| Language            | Python               |
| UI                  | Streamlit            |
| PDF Processing      | PyMuPDF              |
| Retrieval Framework | LangChain            |
| Vector Database     | Pinecone             |
| Embeddings          | Google Generative AI |
| LLM                 | Gemini               |
| Keyword Search      | BM25                 |
| Caching             | Pickle               |
| Deployment          | Streamlit Cloud      |

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/yourusername/voice-of-the-sign.git
cd voice-of-the-sign
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Environment variables

Create a `.env` file:

```env
GOOGLE_API_KEY=your_key_here
PINECONE_API_KEY=your_key_here
```

---

## ğŸ“¥ Ingestion Workflow

```bash
python ingest_local.py
```

Supports:

* Resume after failure
* Incremental updates
* Safe reâ€‘runs
* No duplicate vectors

---

## ğŸš€ Running the App

```bash
streamlit run streamlit_app.py
```

---

## ğŸ”— Reference Linking

All references open directly to the original sermon on MessageHub:

```
https://www.messagehub.info/en/read.do?ref_num=62-0909E
```

This allows users to instantly verify AI responses against primary sources.

---

## ğŸ§ª Example Queries

* *â€œSummarize In His Presenceâ€*
* *â€œWhat does the white horse represent in the Seven Seals?â€*
* *â€œExplain the Laodicean Church Ageâ€*
* *â€œWhat did he say about justification?â€*

---

## ğŸ§© Design Philosophy

This project was intentionally built to demonstrate:

* Data engineering rigor
* LLM safety awareness
* Explainable AI principles
* Scalable ingestion design
* Professional RAG architecture

It is **not** a toy chatbot, but a **researchâ€‘grade retrieval system** designed around realâ€‘world constraints.

---

## ğŸ‘¤ Author

**Aina Adoption Oluwasomidotun**
AI Engineer | Backend Engineer | RAG Systems Builder

Focused on:

* Retrievalâ€‘Augmented Generation
* Explainable AI
* Scalable ingestion pipelines
* LLM safety and grounding

---

## ğŸ“ License

This project is provided for demonstration and educational purposes.

---

### âœ… Recruiter Note

This project demonstrates **endâ€‘toâ€‘end ownership** of:

* Data ingestion
* Indexing and retrieval
* Prompt engineering
* UI integration
* Deployment considerations

It reflects the architectural thinking expected in **productionâ€‘grade AI systems** at serious engineering organizations.
